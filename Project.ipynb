{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bd5b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Section 1 - API Download\n",
    "import sentinelsat\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "import geopandas as gpd\n",
    "import pandas\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Define paths\n",
    "path2 = '/Users/danielnephew/Documents/sia/named'\n",
    "path3 = '/Users/danielnephew/Documents/sia'\n",
    "os.chdir(path3)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "#Create folder for unzipped files\n",
    "if not os.path.exists('unzipped'):\n",
    "    os.mkdir('unzipped')\n",
    "\n",
    "#Hail Sentinel API\n",
    "api = SentinelAPI('dnephew', 'Tartaruga2', 'https://apihub.copernicus.eu/apihub')\n",
    "\n",
    "#Define target area GeoJson\n",
    "my_geojson = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-81.585018,28.402086],[-81.584433,28.40334],[-81.583629,28.403619],[-81.575797,28.403565],[-81.574177,28.399708],[-81.574129,28.397843],[-81.575347,28.397854],[-81.575274,28.397543],[-81.579963,28.397554],[-81.580852,28.3966],[-81.5814,28.396622],[-81.583837,28.399322],[-81.584543,28.400179],[-81.585018,28.402086]]]}}]}\n",
    "footprint = geojson_to_wkt(my_geojson)\n",
    "\n",
    "current_dir = os.getcwd()      \n",
    "\n",
    "#Define target timeframe\n",
    "years = [\n",
    "    2019,2020,2021\n",
    "]\n",
    "\n",
    "#Loop to run API extraction through target years and months\n",
    "for year in years:\n",
    "    for month in range(3,12+1):\n",
    "        date1 = str(year) + str(month-1) + str('01')\n",
    "        date2 = str(year) + str(month) + str('01')\n",
    "        date = (date1,date2)\n",
    "        print(str(month-1) + str('.') + str(year))\n",
    "        try:\n",
    "            products = api.query(\n",
    "                footprint,\n",
    "                date = date,\n",
    "                platformname = 'Sentinel-2',\n",
    "            )\n",
    "            #Sort all images and download with least cloud percentage\n",
    "            products_df = api.to_dataframe(products)\n",
    "            products_df_sorted = products_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "            products_df_sorted = products_df_sorted.head(1)\n",
    "            api.download_all(products_df_sorted.index)\n",
    "        \n",
    "            title = products_df_sorted\n",
    "            for row in title.iterrows():\n",
    "                title1 = title.iterrows\n",
    "                title1 = row[1]['title']\n",
    "\n",
    "            #Unzip files\n",
    "            with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "                zip_ref.extractall('unzipped')\n",
    "            \n",
    "            #Find RGB image, rename, and move to folder\n",
    "            for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "                try:\n",
    "                    for file in files:\n",
    "                        if file.endswith(\"TCI.jp2\"):\n",
    "                            file1 = os.path.join(path, file)\n",
    "                            os.rename(file1,str(month-1)+'.'+str(year)+'.jp2')\n",
    "                            shutil.move(str(month-1)+'.'+str(year)+'.jp2','/Users/danielnephew/Documents/sia/named') \n",
    "                except FileNotFoundError:\n",
    "                    print('No TCI file/Manually add')\n",
    "                    pass\n",
    "            \n",
    "        except KeyError:\n",
    "            print('Error products')\n",
    "            pass\n",
    "\n",
    "try:\n",
    "    product1 = api.query(\n",
    "        footprint,\n",
    "        platformname = 'Sentinel-2',\n",
    "        date = ('20191201', '20191230'),\n",
    "    )\n",
    "    print(\"12.2019\")\n",
    "    product1_df = api.to_dataframe(product1)\n",
    "    product1_df_sorted = product1_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "    product1_df_sorted = product1_df_sorted.head(1)\n",
    "    api.download_all(product1_df_sorted.index)\n",
    "\n",
    "\n",
    "    title = product1_df_sorted\n",
    "    for row in title.iterrows():\n",
    "        title1 = title.iterrows\n",
    "        title1 = row[1]['title']\n",
    "\n",
    "    with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('unzipped')\n",
    "\n",
    "    for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "        for file in files:\n",
    "            try:\n",
    "                if file.endswith(\"TCI.jp2\"):\n",
    "                    file1 = os.path.join(path, file)\n",
    "                    os.rename(file1,'12.2019.jp2')\n",
    "                    shutil.move('12.2019.jp2','/Users/danielnephew/Documents/sia/named') \n",
    "            except FileNotFoundError:\n",
    "                print('No TCI file/Manually add')\n",
    "                pass\n",
    "            \n",
    "#API erros exception\n",
    "#Attempt to download\n",
    "except KeyError:\n",
    "    print('Error product1')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    product2 = api.query(\n",
    "        footprint,\n",
    "        platformname = 'Sentinel-2',\n",
    "        date = ('20201201', '2021101'),\n",
    "    )\n",
    "    print(\"12.2020\")\n",
    "    product2_df = api.to_dataframe(product2)\n",
    "    product2_df_sorted = product2_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "    product2_df_sorted = product2_df_sorted.head(1)\n",
    "    api.download_all(product2_df_sorted.index)\n",
    "    title = product2_df_sorted\n",
    "    for row in title.iterrows():\n",
    "        title1 = title.iterrows\n",
    "        title1 = row[1]['title']\n",
    "\n",
    "    with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('unzipped')\n",
    "\n",
    "    for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "        for file in files:\n",
    "            try:\n",
    "                if file.endswith(\"TCI.jp2\"):\n",
    "                    file1 = os.path.join(path, file)\n",
    "                    os.rename(file1,'12.2020.jp2')\n",
    "                    shutil.move('12.2020.jp2','/Users/danielnephew/Documents/sia/named')\n",
    "            except FileNotFoundError:\n",
    "                print('No TCI file/Manually add')\n",
    "                pass\n",
    "            \n",
    "except KeyError:\n",
    "    print('Error product2')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    product3 = api.query(\n",
    "        footprint,\n",
    "        platformname = 'Sentinel-2',\n",
    "        date = ('20190101', '20190201'),\n",
    "        cloudcoverpercentage = (0,10),\n",
    "        limit=1\n",
    "    )\n",
    "    print(\"1.2019\")\n",
    "    product3_df = api.to_dataframe(product3)\n",
    "    product3_df_sorted = product3_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "    product3_df_sorted = product3_df_sorted.head(1)\n",
    "    api.download_all(product3_df_sorted.index)\n",
    "    title = product3_df_sorted\n",
    "    for row in title.iterrows():\n",
    "        title1 = title.iterrows\n",
    "        title1 = row[1]['title']\n",
    "\n",
    "    with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('unzipped')\n",
    "\n",
    "    for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "        for file in files:\n",
    "            try:\n",
    "                if file.endswith(\"TCI_10m.jp2\"):\n",
    "                    file1 = os.path.join(path, file)\n",
    "                    os.rename(file1,'1.2019.jp2')\n",
    "                    shutil.move('1.2019.jp2','/Users/danielnephew/Documents/sia/named')\n",
    "            except FileNotFoundError:\n",
    "                print('No TCI file/Manually add')\n",
    "                pass\n",
    "            \n",
    "except KeyError:\n",
    "    print('Error product3')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    #API Dataset Offline\n",
    "    product4 = api.query(\n",
    "        footprint,\n",
    "        platformname = 'Sentinel-2',\n",
    "        date = ('2020101', '2020130'),\n",
    "    )\n",
    "    print(\"1.2020\")\n",
    "    product4_df = api.to_dataframe(product4)\n",
    "    product4_df_sorted = product4_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "    product4_df_sorted = product4_df_sorted.head(1)\n",
    "    api.download_all(product4_df_sorted.index)\n",
    "    title = product4_df_sorted\n",
    "    for row in title.iterrows():\n",
    "        title1 = title.iterrows\n",
    "        title1 = row[1]['title']\n",
    "\n",
    "    with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('unzipped')\n",
    "\n",
    "    for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "        for file in files:\n",
    "            try:\n",
    "                if file.endswith(\"TCI.jp2\"):\n",
    "                    file1 = os.path.join(path, file)\n",
    "                    os.rename(file1,'1.2020.jp2')\n",
    "                    shutil.move('1.2020.jp2','/Users/danielnephew/Documents/sia/named')\n",
    "            except FileNotFoundError:\n",
    "                print('No TCI file/Manually add')\n",
    "                pass\n",
    "            \n",
    "except KeyError:\n",
    "    print('Error product4')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    #API Dataset Offline\n",
    "    product5 = api.query(\n",
    "        footprint,\n",
    "        platformname = 'Sentinel-2',\n",
    "        date = ('2021101', '2021130'),\n",
    "    )\n",
    "    print(\"1.2021\")\n",
    "    product5_df = api.to_dataframe(product5)\n",
    "    product5_df_sorted = product5_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "    product5_df_sorted = product5_df_sorted.head(1)\n",
    "    api.download_all(product5_df_sorted.index)\n",
    "    title = product5_df_sorted\n",
    "    for row in title.iterrows():\n",
    "        title1 = title.iterrows\n",
    "        title1 = row[1]['title']\n",
    "\n",
    "    with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('unzipped')\n",
    "\n",
    "    for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "        for file in files:\n",
    "            try:\n",
    "                if file.endswith(\"TCI.jp2\"):\n",
    "                    file1 = os.path.join(path, file)\n",
    "                    os.rename(file1,'1.2021.jp2')\n",
    "                    shutil.move('1.2021.jp2','/Users/danielnephew/Documents/sia/named')\n",
    "            except FileNotFoundError:\n",
    "                print('No TCI file/Manually add')\n",
    "                pass\n",
    "            \n",
    "except KeyError:\n",
    "    print('Error product5')\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    product6 = api.query(\n",
    "        footprint,\n",
    "        platformname = 'Sentinel-2',\n",
    "        date = ('20211201', '20211230'),\n",
    "    )\n",
    "    print(\"12.2021\")\n",
    "    product6_df = api.to_dataframe(product6)\n",
    "    product6_df_sorted = product6_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "    product6_df_sorted = product6_df_sorted.head(1)\n",
    "    api.download_all(product6_df_sorted.index)\n",
    "    title = product6_df_sorted\n",
    "    for row in title.iterrows():\n",
    "        title1 = title.iterrows\n",
    "        title1 = row[1]['title']\n",
    "\n",
    "    with zipfile.ZipFile(str(title1) + str('.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('unzipped')\n",
    "\n",
    "    for path, currentDirectory, files in os.walk('/Users/danielnephew/Documents/sia/unzipped/'+str(title1)+'.SAFE'):\n",
    "        for file in files:\n",
    "            try:\n",
    "                if file.endswith(\"TCI.jp2\"):\n",
    "                    file1 = os.path.join(path, file)\n",
    "                    os.rename(file1,'12.2021.jp2')\n",
    "                    shutil.move('12.2021.jp2','/Users/danielnephew/Documents/sia/named') \n",
    "            except FileNotFoundError:\n",
    "                print('No TCI file/Manually add')\n",
    "                pass\n",
    "\n",
    "except KeyError:\n",
    "    print('Error product6')\n",
    "    pass\n",
    "\n",
    "print('Downloads complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096a1e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Section 2 - Image Clipping\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Change UTM coordinates to projected\n",
    "my_geojson2 = [{\"type\":\"Polygon\",\"coordinates\":[[[442718.75876470795, 3141853.2678216496], [442732.4362107091, 3141764.9038605513], [442797.26849554444, 3141599.516183481], [443017.22039175703, 3141604.877664531], [442984.28594074846, 3141702.3080344144], [442952.87886495434, 3141852.1335630943], [442718.75876470795, 3141853.2678216496]]]}]\n",
    "\n",
    "print(my_geojson2)\n",
    "\n",
    "#Define folder to export clipped image\n",
    "output_folder = 'clipped'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "#Define path\n",
    "path4 = path3+'/clipped'\n",
    "os.chdir(path4)\n",
    "\n",
    "ext = ('.jp2')\n",
    "\n",
    "#Loop to run clipping for each images\n",
    "for file in os.listdir(path2):\n",
    "    if file.endswith(ext):\n",
    "        with rasterio.open(path2+'/'+file) as img:\n",
    "            clipped, transform = mask(img, my_geojson2, crop=True)\n",
    "            meta = img.meta.copy()\n",
    "            meta.update(\n",
    "                {\n",
    "                    \"transform\": transform,\n",
    "                    \"height\":clipped.shape[1],\n",
    "                    \"width\":clipped.shape[2]\n",
    "                }\n",
    "            )\n",
    "            name = str(file)\n",
    "            with rasterio.open(name, 'w', **meta) as dst:\n",
    "                dst.write(clipped)\n",
    "            print('Writing complete')\n",
    "            print(file)\n",
    "            from rasterio.plot import show\n",
    "            show(clipped)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4bede1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Section 3 - Object Detection\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import shapes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "from collections import Counter\n",
    "\n",
    "#Define path\n",
    "path3 = '/Users/danielnephew/Documents/sia'\n",
    "os.chdir(path3+'/clipped')\n",
    "\n",
    "#7.2019 and 6.2021 discarted due to cloud\n",
    "\n",
    "#No loop due to bug\n",
    "#Loop per file name\n",
    "name = ['1.2019.jp2','2.2019.jp2','3.2019.jp2','4.2019.jp2','5.2019.jp2','6.2019.jp2','8.2019.jp2','9.2019.jp2','10.2019.jp2','11.2019.jp2','12.2019.jp2',\n",
    "        '2.2020.jp2','12.2020.jp2','11.2020.jp2','12.2020.jp2',\n",
    "        '2.2021.jp2','3.2021.jp2','4.2021.jp2','5.2021.jp2','7.2021.jp2','8.2021.jp2','9.2021.jp2','10.2021.jp2','11.2021.jp2','12.2021.jp2',\n",
    "        ]\n",
    "#Define parameters for each optimal value for vehicle extraction for each image\n",
    "#Skips images that require more tailored extraction\n",
    "param = [50,80,80,80,80,80,80,90,80,80,70,\n",
    "         80,80,100,1,\n",
    "         1,100,100,110,104,100,100,80,1,1\n",
    "        ]\n",
    "\n",
    "#Define loop for two variables\n",
    "dic=dict(zip(name, param))\n",
    "for x,y in zip(name, param):\n",
    "    globals()[x] = y\n",
    "    file = x\n",
    "    my_image= rasterio.open(file)\n",
    "    print(file)\n",
    "\n",
    "    red = my_image.read(1)\n",
    "    green = my_image.read(2)\n",
    "    blue = my_image.read(3)\n",
    "    show(blue, cmap='Blues')\n",
    "\n",
    "    red = np.float32(red)\n",
    "    green = np.float32(green)\n",
    "    blue = np.float32(blue)\n",
    "    print('blue')\n",
    "    print(blue)\n",
    "    print('green')\n",
    "    print(green)\n",
    "    print('red')\n",
    "    print(red)\n",
    "    \n",
    "    red = np.float32(red)\n",
    "    green = np.float32(green)\n",
    "    blue = np.float32(blue)\n",
    "    car_index = np.zeros(blue.shape)\n",
    "    car_index[blue > y] = 1\n",
    "    plt.imshow(car_index)\n",
    "    car_index = car_index.astype('float32')\n",
    "    my_shapes = shapes(car_index)\n",
    "    \n",
    "#Auxiliary data to manually analyze and find optimal value for extraction\n",
    "#Utilize histogram, data arrays, and most common value in array\n",
    "    fig, (ax1, ax2) = plt.subplots(2,2)\n",
    "    blue_data = blue[np.not_equal(blue, my_image.nodata)]\n",
    "    red_data = red[np.not_equal(red, my_image.nodata)]\n",
    "    green_data = green[np.not_equal(green, my_image.nodata)]\n",
    "    bin_number = 80\n",
    "    ax1[0].hist(blue_data, color='blue', bins=bin_number)\n",
    "    ax1[1].hist(red_data, color='red', bins=bin_number)\n",
    "    ax2[0].hist(green_data, color='green', bins=bin_number)\n",
    "    ax1[0].set_title('Blue Histogram')\n",
    "    ax1[1].set_title('Red Histogram')\n",
    "    ax2[0].set_title('Green Histogram')\n",
    "    fig.tight_layout()\n",
    "    b = Counter(red_data)\n",
    "    print (b.most_common())\n",
    "    car_index = np.zeros(blue.shape)\n",
    "    car_index[blue > y] = 1\n",
    "    plt.imshow(car_index)\n",
    "    car_index = car_index.astype('float32')\n",
    "    my_shapes = shapes(car_index)\n",
    "\n",
    "\n",
    "        #Manual adjustment\n",
    "    if file =='12.2020.jp2':\n",
    "        red = np.float32(red)\n",
    "        green = np.float32(green)\n",
    "        blue = np.float32(blue)\n",
    "        print('red')\n",
    "        print(red)\n",
    "        car_index = np.zeros(blue.shape)\n",
    "        car_index[blue<95] = 1\n",
    "        car_index[blue==92] = 0\n",
    "        car_index[blue>99] = 0\n",
    "        car_index[blue<80] = 0\n",
    "        plt.imshow(car_index)\n",
    "        car_index = car_index.astype('float32')\n",
    "        my_shapes = shapes(car_index)\n",
    "        \n",
    "        #Manual adjustment\n",
    "    if file =='2.2021.jp2':\n",
    "        red = np.float32(red)\n",
    "        green = np.float32(green)\n",
    "        blue = np.float32(blue)\n",
    "        car_index = np.zeros(blue.shape)\n",
    "        car_index[blue > 70] = 1\n",
    "        car_index[blue== 90] = 0\n",
    "        car_index[blue== 94] = 0\n",
    "        car_index[red > 70] = 1\n",
    "        car_index[red == 70] = 0\n",
    "        car_index[red == 74] = 0\n",
    "        plt.imshow(car_index)\n",
    "        car_index = car_index.astype('float32')\n",
    "        my_shapes = shapes(car_index)\n",
    "        \n",
    "        #Manual adjustment\n",
    "    if file =='12.2021.jp2':\n",
    "        red = np.float32(red)\n",
    "        green = np.float32(green)\n",
    "        blue = np.float32(blue)\n",
    "        car_index = np.zeros(blue.shape)\n",
    "        car_index[blue > 90] = 1\n",
    "        car_index[green > 70] = 1\n",
    "        plt.imshow(car_index)\n",
    "        car_index = car_index.astype('float32')\n",
    "        my_shapes = shapes(car_index)\n",
    "        \n",
    "        #Manual adjustment\n",
    "    if file =='11.2021.jp2':\n",
    "        red = np.float32(red)\n",
    "        green = np.float32(green)\n",
    "        blue = np.float32(blue)\n",
    "        car_index = np.zeros(blue.shape)\n",
    "        car_index[blue > 90] = 1\n",
    "        car_index[red == 70] = 0\n",
    "        car_index[red == 74] = 0\n",
    "        car_index[red == 78] = 0\n",
    "        plt.imshow(car_index)\n",
    "        car_index = car_index.astype('float32')\n",
    "        my_shapes = shapes(car_index)\n",
    "\n",
    "#Define output folder\n",
    "    os.chdir(path3)\n",
    "    output_folder = 'shapes'\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "#Transform CRS\n",
    "    def transform_coordinates(pair):\n",
    "        geo_coords = my_image.xy(pair[1],pair[0])\n",
    "        return [geo_coords[0], geo_coords[1]]\n",
    "\n",
    "    for car in my_shapes:\n",
    "        coordinates = [transform_coordinates(pair) for pair in car[0]['coordinates'][0]]\n",
    "        break\n",
    "    output = []\n",
    "    for car_shape in my_shapes:\n",
    "        coords = car_shape[0]['coordinates'][0]\n",
    "        geographic_coords = [transform_coordinates(pair) for pair in coords]\n",
    "        output.append({\n",
    "            'geometry' : {\n",
    "                'type':'Polygon',\n",
    "                'coordinates': [geographic_coords],\n",
    "                },\n",
    "            'properties': {},\n",
    "        }) \n",
    "    \n",
    "#Extract second largest area\n",
    "#First largest area is always a false positive, discart\n",
    "    data_to_write = gpd.GeoDataFrame.from_features(output, crs='epsg:32617')\n",
    "    name = str(file)\n",
    "    data_to_write.to_file('shapes/'+str(file)+'_car_shape.shp')\n",
    "\n",
    "    data = gpd.read_file('shapes/'+str(file)+'_car_shape.shp')\n",
    "    data = data.to_crs('epsg:3857')\n",
    "\n",
    "    data['area'] = data['geometry'].area \n",
    "\n",
    "    title = file.replace('.jp2', '')\n",
    "    sorted = data.sort_values(['area'], ascending = False)\n",
    "    extract = sorted.head(2)\n",
    "    sorted2 = extract.sort_values(['area'], ascending = True)\n",
    "    extract2 = sorted2.head(1)\n",
    "    write = extract2.to_crs('epsg:32617')\n",
    "    os.chdir(path3+'/carareas')\n",
    "    write.to_file(str(title)+\".shp\")\n",
    "    os.chdir(path3+'/clipped')\n",
    "\n",
    "#Shape extraction exceptions due to car clusters being separated\n",
    "#Exceptions\n",
    "    if file =='2.2019.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustments\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(1)\n",
    "        print(sorted)\n",
    "        write = extract.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"2.2019.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='1.2019.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustments\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        print(sorted)\n",
    "        drop = sorted.drop(3)\n",
    "        write = drop.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"1.2019.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='2.2021.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustments\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(10)\n",
    "        sorted2 = extract.sort_values(['area'], ascending = True)\n",
    "        extract2 = sorted2.head(6)\n",
    "        sorted3 = extract2.sort_values(['area'], ascending = False)\n",
    "        extract3 = sorted3.head(3)\n",
    "        write = extract3.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"2.2021.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='11.2019.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustment\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(2)\n",
    "        sorted2 = extract.sort_values(['area'], ascending = True)\n",
    "        extract2 = sorted2.head(1)\n",
    "        write = extract2.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"11.2019.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='9.2019.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustment\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(4)\n",
    "        sorted2 = extract.sort_values(['area'], ascending = True)\n",
    "        extract2 = sorted2.head(3)\n",
    "        write = extract2.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"9.2019.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='12.2020.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustment\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(7)\n",
    "        sorted2 = extract.sort_values(['area'], ascending = True)\n",
    "        extract2 = sorted2.head(6)\n",
    "        write = extract2.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"12.2020.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='11.2020.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustment\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(16)\n",
    "        sorted2 = extract.sort_values(['area'], ascending = True)\n",
    "        extract2 = sorted2.head(15)\n",
    "        sorted3 = extract2.sort_values(['area'], ascending = False)\n",
    "        extract3 = sorted3.head(12)\n",
    "        write = extract3.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"11.2020.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='11.2021.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustment\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        print(sorted)\n",
    "        drop = sorted.drop(27)\n",
    "        extract = drop.head(20)\n",
    "        write = extract.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"11.2021.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='10.2019.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustments\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(1)\n",
    "        print(sorted)\n",
    "        write = extract.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"10.2019.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='10.2021.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustments\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(1)\n",
    "        print(sorted)\n",
    "        write = extract.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"10.2021.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')\n",
    "    if file =='12.2019.jp2':\n",
    "        title = file.replace('.jp2', '')\n",
    "        #Manual adjustments\n",
    "        sorted = data.sort_values(['area'], ascending = False)\n",
    "        extract = sorted.head(1)\n",
    "        print(sorted)\n",
    "        print(data)\n",
    "        write = data.to_crs('epsg:32617')\n",
    "        os.chdir(path3+'/carareas')\n",
    "        write.to_file(\"12.2019.shp\")\n",
    "        os.chdir(path3+'/clipped')\n",
    "        print('Exception: Replaced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 4 - Results Extraction\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "#Define paths\n",
    "path3 = '/Users/danielnephew/Documents/sia'\n",
    "os.chdir(path3)\n",
    "path5 = path3+'/carareas/'\n",
    "\n",
    "#Create data array output for each year\n",
    "output = []\n",
    "\n",
    "#Append 2019 shape areas to output\n",
    "control = '2019.shp'\n",
    "for file in os.listdir(path5):\n",
    "    if file.endswith(control):\n",
    "        data = gpd.read_file(path5+file, crs='epsg:32617')\n",
    "        data = data.to_crs('epsg:3857')\n",
    "        title = file.replace('.shp', '')\n",
    "        for row in data.iterrows():\n",
    "            area = row[1]['geometry'].area\n",
    "            output.append({\n",
    "                'index': title,\n",
    "                'area': area,\n",
    "            })\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#Append 2020 shape areas to output\n",
    "sample2020 = '2020.shp'\n",
    "for file in os.listdir(path5):\n",
    "    if file.endswith(sample2020):\n",
    "        data = gpd.read_file(path5+file, crs='epsg:32617')\n",
    "        data = data.to_crs('epsg:3857')\n",
    "        title = file.replace('.ex', '')\n",
    "        for row in data.iterrows():\n",
    "                area = row[1]['geometry'].area\n",
    "                output.append({\n",
    "                    'index': title,\n",
    "                    'area': area,\n",
    "                })\n",
    "    else:\n",
    "        continue \n",
    "\n",
    "#Append 2021 shape areas to output\n",
    "sample2021 = '2021.shp'\n",
    "for file in os.listdir(path5):\n",
    "    if file.endswith(sample2021):\n",
    "        data = gpd.read_file(path5+file, crs='epsg:32617')\n",
    "        data = data.to_crs('epsg:3857')\n",
    "        title = file.replace('.ex', '')\n",
    "        for row in data.iterrows():\n",
    "                area = row[1]['geometry'].area\n",
    "                output.append({\n",
    "                    'index': title,\n",
    "                    'area': area,\n",
    "                })\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#Extract data into CSV for analysis\n",
    "output = pd.DataFrame(output)\n",
    "output.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
